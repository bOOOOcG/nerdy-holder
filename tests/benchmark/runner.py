"""Benchmark è¿è¡Œå™¨"""

import time
import psutil
import statistics
from datetime import datetime

from .utils import HolderStatusReader
from .scenarios import *


class BenchmarkRunner:
    """Benchmarkè¿è¡Œå™¨"""

    def __init__(self):
        self.scenarios = [
            StarvationScenario(),
            ReleaseScenario(),
            FluctuationScenario(),
            PressureScenario(),
            ExtremeScenario(),
            ShockScenario(),
            SustainedScenario(),
            BidirectionalScenario(),
            NonlinearScenario(),
        ]
        self.results = []
        self.holder_status = HolderStatusReader()

    def check_holder(self):
        """æ£€æŸ¥holder"""
        if not self.holder_status.is_available():
            print("\næ— æ³•æ£€æµ‹åˆ°Holderè¿è¡Œ")
            print("   è¯·å…ˆè¿è¡Œ: python run_holder.py --fixed-target 80")
            return False

        status = self.holder_status.read_status()
        print(f"\nHolderè¿è¡Œä¸­")
        print(f"   ç›®æ ‡: {status['current_target']:.1f}%")
        print(f"   æŒæœ‰: {status['holding_mb']:.0f}MB")
        print(f"   ç³»ç»Ÿ: {status['system_memory']:.1f}%")

        return True

    def run_all(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("\n" + "="*80)
        print("ğŸ¤“ Nerdy Holder Benchmarker")
        print("="*80)
        print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ç³»ç»Ÿå†…å­˜: {psutil.virtual_memory().total / (1024**3):.1f} GB")
        print(f"æµ‹è¯•åœºæ™¯: {len(self.scenarios)} ä¸ª")
        print("="*80)

        if not self.check_holder():
            return

        print("\nå‡†å¤‡å°±ç»ª")
        print("\næŒ‰ Enter å¼€å§‹...")
        try:
            input()
        except KeyboardInterrupt:
            print("\nå–æ¶ˆ")
            return

        print("\nå¼€å§‹æµ‹è¯•...\n")
        time.sleep(2)

        for i, scenario in enumerate(self.scenarios, 1):
            print(f"\n{'='*80}")
            print(f"æµ‹è¯• {i}/{len(self.scenarios)}")
            print(f"{'='*80}")

            try:
                metrics = scenario.run()

                if metrics:
                    self.results.append({
                        'name': scenario.name,
                        'metrics': metrics
                    })

                    self.print_result(scenario.name, metrics)

                if i < len(self.scenarios):
                    print("\nä¼‘æ¯ 5 ç§’...")
                    time.sleep(5)

            except KeyboardInterrupt:
                print("\n\nä¸­æ–­")
                break
            except Exception as e:
                print(f"\nå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()

        if self.results:
            self.print_summary()

    def print_result(self, name, metrics):
        """æ‰“å°ç»“æœ"""
        print(f"\n{name} - ç»“æœ:")
        print("-" * 80)

        if metrics.get('response_time'):
            print(f"å“åº”é€Ÿåº¦: {metrics['response_time']:.1f}ç§’")
        else:
            print(f"å“åº”é€Ÿåº¦: >åœºæ™¯æ—¶é•¿")

        print(f"å¹³å‡è¯¯å·®: {metrics['avg_error']:.2f}%")
        print(f"æœ€å¤§è¯¯å·®: {metrics['max_error']:.2f}%")
        print(f"ç¨³å®šæ€§:   {metrics['stability']:.2f}%")
        print(f"è°ƒæ•´æ¬¡æ•°: {metrics['adjustments']}æ¬¡")
        print(f"è°ƒæ•´é¢‘ç‡: {metrics['adjustment_rate']:.1f}æ¬¡/åˆ†é’Ÿ")

        actual = metrics.get('holder_delta', 0)
        expected = metrics.get('expect_delta', 0)
        test_size = metrics.get('test_size_mb', 0)

        print(f"\næµ‹è¯•é‡: {test_size:.0f}MB")
        if expected != 0:
            print(f"Holderå“åº”: {actual:+.0f}MB (é¢„æœŸ{expected:+.0f}MB)")
            response_rate = (abs(actual) / abs(expected) * 100) if expected != 0 else 0
            print(f"å“åº”ç‡: {response_rate:.1f}%")
        else:
            print(f"Holderå˜åŒ–: {actual:+.0f}MB")

        score = self.calculate_score(metrics)
        grade = self.get_grade(score)
        print(f"\nè¯„åˆ†: {score:.1f}/100 ({grade})")

    def calculate_score(self, m):
        """è®¡ç®—è¯„åˆ†"""
        # å“åº”é€Ÿåº¦ (35åˆ†)
        if m.get('response_time'):
            if m['response_time'] < 5:
                response_score = 35
            elif m['response_time'] < 10:
                response_score = 30
            elif m['response_time'] < 15:
                response_score = 25
            else:
                response_score = 15
        else:
            response_score = 10

        # å‡†ç¡®åº¦ (30åˆ†)
        avg_error = m['avg_error']
        if avg_error < 1:
            accuracy_score = 30
        elif avg_error < 2:
            accuracy_score = 25
        elif avg_error < 3:
            accuracy_score = 20
        else:
            accuracy_score = max(0, 30 - avg_error * 4)

        # ç¨³å®šæ€§ (15åˆ†)
        stability = m['stability']
        if stability < 1:
            stability_score = 15
        elif stability < 2:
            stability_score = 12
        elif stability < 3:
            stability_score = 10
        else:
            stability_score = max(0, 15 - stability * 2)

        # Holderå“åº”ç‡ (20åˆ†)
        actual = abs(m.get('holder_delta', 0))
        expected = abs(m.get('expect_delta', 0))

        if expected > 0:
            response_rate = actual / expected
            if response_rate > 0.8:
                holder_score = 20
            elif response_rate > 0.6:
                holder_score = 15
            elif response_rate > 0.4:
                holder_score = 10
            else:
                holder_score = 5
        else:
            holder_score = 15

        return response_score + accuracy_score + stability_score + holder_score

    def get_grade(self, score):
        """è¯„çº§"""
        if score >= 90:
            return "S ä¼˜ç§€"
        elif score >= 80:
            return "A è‰¯å¥½"
        elif score >= 70:
            return "B ä¸­ç­‰"
        elif score >= 60:
            return "C åŠæ ¼"
        else:
            return "D ä¸åŠæ ¼"

    def print_summary(self):
        """æ€»ç»“"""
        print("\n" + "="*80)
        print("æµ‹è¯•æ€»ç»“")
        print("="*80)

        print(f"\nå®Œæˆ: {len(self.results)}/{len(self.scenarios)}\n")

        print("åœºæ™¯å¾—åˆ†:")
        print("-" * 80)
        print(f"{'åœºæ™¯':<30} {'å“åº”(s)':<10} {'è¯¯å·®':<10} {'Holderå“åº”':<15} {'å¾—åˆ†':<10}")
        print("-" * 80)

        scores = []
        for r in self.results:
            m = r['metrics']
            score = self.calculate_score(m)
            scores.append(score)

            resp = f"{m['response_time']:.1f}" if m.get('response_time') else "N/A"

            actual = m.get('holder_delta', 0)
            expected = m.get('expect_delta', 0)
            if expected != 0:
                response_rate = (abs(actual) / abs(expected) * 100) if expected != 0 else 0
                holder_str = f"{response_rate:.0f}%"
            else:
                holder_str = f"{actual:+.0f}MB"

            print(f"{r['name']:<30} {resp:<10} {m['avg_error']:<10.2f} {holder_str:<15} {score:<10.1f}")

        print("-" * 80)
        avg = sum(scores) / len(scores)
        print(f"\næ€»åˆ†: {avg:.1f}/100")
        print(f"è¯„çº§: {self.get_grade(avg)}")

        # åˆ†æ
        print(f"\nå…³é”®æŒ‡æ ‡:")
        all_errors = [r['metrics']['avg_error'] for r in self.results]
        all_stabilities = [r['metrics']['stability'] for r in self.results]
        print(f"  å¹³å‡è¯¯å·®: {statistics.mean(all_errors):.2f}%")
        print(f"  å¹³å‡ç¨³å®šæ€§: {statistics.mean(all_stabilities):.2f}%")

        print("\n" + "="*80)

        self.save_report(avg)

    def save_report(self, score):
        """ä¿å­˜æŠ¥å‘Š"""
        filename = f"benchmark_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write("Nerdy Holder Benchmarker æµ‹è¯•æŠ¥å‘Š\n")
                f.write("="*80 + "\n")
                f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now()}\n")
                f.write(f"æ€»åˆ†: {score:.1f}/100\n\n")

                for r in self.results:
                    f.write(f"\nåœºæ™¯: {r['name']}\n")
                    f.write("-"*80 + "\n")
                    for k, v in r['metrics'].items():
                        f.write(f"{k}: {v}\n")

            print(f"\næŠ¥å‘Š: {filename}")
        except Exception as e:
            print(f"\nä¿å­˜å¤±è´¥: {e}")
